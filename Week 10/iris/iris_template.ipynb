{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Classification on Iris Flowers Dataset\n",
    "\n",
    "This is very simple and basic example of training a model for classification of Iris flowers. \n",
    "In this notebook we will concentrate on the evaluation of the model and not the preprocessing, training and tuning of the model.\n",
    "\n",
    "First we need to import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic infor about dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes and tjeir frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of the data\n",
    "# Hint: use sns.pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proprocessing of the Data\n",
    "\n",
    "This step will consist of only two parts:\n",
    "1. Dividing the data into features and labels.\n",
    "2. Splitting the data into training and testing sets. Look at [this](https://illustrated-machine-learning.github.io/#/machine-learning-engineering/introduction#training-and-holdout-sets) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets and print their shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training and Testing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training method\n",
    "def train_model(model, x, y, conf=\"\"):\n",
    "    # fit the model\n",
    "   \n",
    "    # make predictions\n",
    "   \n",
    "    # get accuracy of predictions\n",
    "    \n",
    "    print(f\"Model - {conf}\")\n",
    "    print(f\"Train Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics that are most commonly used for classification problems are:\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F1 Score\n",
    "5. Confusion Matrix\n",
    "\n",
    "For preview of these metrics, look at [this](https://illustrated-machine-learning.github.io/#/machine-learning/metrics) page.\n",
    "T understand micro, macro and weighted averaging, check scikit-learn documentation of the wanted metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "def visualize_confusion_martix(y, confusion_matrix):\n",
    "    cm = pd.DataFrame(confusion_matrix, index=y.unique(), columns=y.unique())\n",
    "    # plot using seaborn\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Define testing method\n",
    "def test_model(model, x, y, conf=\"\"):\n",
    "    # make predictions\n",
    "    \n",
    "    # get accuracy of predictions\n",
    "    \n",
    "    # get confusion matrix\n",
    "    \n",
    "    # get classification report\n",
    "    \n",
    "    print(f\"Model - {conf}\")\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "    visualize_confusion_martix(y, y_pred, cm)\n",
    "    print(f\"Classification Report:\\n{cr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline  model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Default Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
